{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7910277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright [2025] [KTH Royal Institute of Technology] \n",
    "# Licensed under the Educational Community License, Version 2.0 (ECL-2.0)\n",
    "# This file is part of the Computer Lab 1 for EL2805 - Reinforcement Learning.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import random\n",
    "\n",
    "# Implemented methods\n",
    "methods = ['DynProg', 'ValIter', 'Q_learning']\n",
    "\n",
    "# Some colours\n",
    "LIGHT_RED    = '#FFC4CC'\n",
    "LIGHT_GREEN  = '#95FD99'\n",
    "BLACK        = '#000000'\n",
    "WHITE        = '#FFFFFF'\n",
    "LIGHT_PURPLE = '#E8D0FF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf50846",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Maze:\n",
    "\n",
    "    # Actions\n",
    "    STAY       = 0\n",
    "    MOVE_LEFT  = 1\n",
    "    MOVE_RIGHT = 2\n",
    "    MOVE_UP    = 3\n",
    "    MOVE_DOWN  = 4\n",
    "\n",
    "    # Give names to actions\n",
    "    actions_names = {\n",
    "        STAY: \"stay\",\n",
    "        MOVE_LEFT: \"move left\",\n",
    "        MOVE_RIGHT: \"move right\",\n",
    "        MOVE_UP: \"move up\",\n",
    "        MOVE_DOWN: \"move down\"\n",
    "    }\n",
    "\n",
    "    # Reward values \n",
    "    STEP_REWARD = 0\n",
    "    GOAL_REWARD = 1\n",
    "    IMPOSSIBLE_REWARD = 0\n",
    "    MINOTAUR_REWARD = 0\n",
    "\n",
    "    def __init__(self, maze):\n",
    "        \"\"\" Constructor of the environment Maze.\n",
    "        \"\"\"\n",
    "        self.maze                     = maze\n",
    "        self.actions                  = self.__actions()\n",
    "        self.states, self.map         = self.__states()\n",
    "        self.n_actions                = len(self.actions)\n",
    "        self.n_states                 = len(self.states)\n",
    "        self.transition_probabilities = self.__transitions()\n",
    "        self.rewards                  = self.__rewards()\n",
    "\n",
    "    def __actions(self):\n",
    "        actions = dict()\n",
    "        actions[self.STAY]       = (0, 0)\n",
    "        actions[self.MOVE_LEFT]  = (0,-1)\n",
    "        actions[self.MOVE_RIGHT] = (0, 1)\n",
    "        actions[self.MOVE_UP]    = (-1,0)\n",
    "        actions[self.MOVE_DOWN]  = (1,0)\n",
    "        return actions\n",
    "\n",
    "    def __states(self):\n",
    "        \n",
    "        states = dict()\n",
    "        map = dict()\n",
    "        s = 0\n",
    "        m=0\n",
    "        for m in range(2):\n",
    "            for i in range(self.maze.shape[0]):\n",
    "                for j in range(self.maze.shape[1]):\n",
    "                    for k in range(self.maze.shape[0]):\n",
    "                        for l in range(self.maze.shape[1]):\n",
    "                            if self.maze[i,j] != 1:\n",
    "                                states[s] = ((i, j), (k,l), m)\n",
    "                                map[((i,j), (k,l), m)] = s\n",
    "                                s += 1\n",
    "        \n",
    "        states[s] = 'Eaten'\n",
    "        map['Eaten'] = s\n",
    "        s += 1\n",
    "        \n",
    "        states[s] = 'Win'\n",
    "        map['Win'] = s\n",
    "        s += 1\n",
    "\n",
    "        states[s] = 'Terminal'\n",
    "        map['Terminal'] = s\n",
    "        \n",
    "        return states, map\n",
    "\n",
    "\n",
    "    def __move(self, state, action):               \n",
    "        \"\"\" Makes a step in the maze, given a current position and an action. \n",
    "            If the action STAY or an inadmissible action is used, the player stays in place.\n",
    "        \n",
    "            :return list of tuples next_state: Possible states ((x,y), (x',y')) on the maze that the system can transition to.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.states[state] == 'Eaten' or self.states[state] == 'Win' or self.states[state] == 'Terminal': # In these states, the game is over\n",
    "            return ['Terminal']\n",
    "        \n",
    "        else: # Compute the future possible positions given current (state, action)\n",
    "            row_player = self.states[state][0][0] + self.actions[action][0] # Row of the player's next position \n",
    "            col_player = self.states[state][0][1] + self.actions[action][1] # Column of the player's next position \n",
    "            \n",
    "            # Is the player getting out of the limits of the maze or hitting a wall?\n",
    "            impossible_action_player = not((0 <= row_player < self.maze.shape[0]) and (0 <= col_player < self.maze.shape[1]) and self.maze[row_player,col_player] != 1)\n",
    "            \n",
    "            actions_minotaur = [[0, -1], [0, 1], [-1, 0], [1, 0]] # Possible moves for the Minotaur\n",
    "            rows_minotaur, cols_minotaur = [], []\n",
    "            for i in range(len(actions_minotaur)):\n",
    "                # Is the minotaur getting out of the limits of the maze?\n",
    "                impossible_action_minotaur = (self.states[state][1][0] + actions_minotaur[i][0] == -1) or \\\n",
    "                                             (self.states[state][1][0] + actions_minotaur[i][0] == self.maze.shape[0]) or \\\n",
    "                                             (self.states[state][1][1] + actions_minotaur[i][1] == -1) or \\\n",
    "                                             (self.states[state][1][1] + actions_minotaur[i][1] == self.maze.shape[1])\n",
    "            \n",
    "                if not impossible_action_minotaur:\n",
    "                    rows_minotaur.append(self.states[state][1][0] + actions_minotaur[i][0])\n",
    "                    cols_minotaur.append(self.states[state][1][1] + actions_minotaur[i][1])  \n",
    "          \n",
    "\n",
    "            # Based on the impossiblity check return the next possible states.\n",
    "            if impossible_action_player: # The action is not possible, so the player remains in place\n",
    "                states = []\n",
    "                for i in range(len(rows_minotaur)):\n",
    "                    \n",
    "                    if self.states[state][0][0] == rows_minotaur[i] and self.states[state][0][1] == cols_minotaur[i]:\n",
    "                        states.append('Eaten')\n",
    "                    \n",
    "                    elif self.maze[self.states[state][0][0], self.states[state][0][1]] == 2 and self.states[state][2] == 1:\n",
    "                        states.append('Win')\n",
    "                \n",
    "                    else:     # The player remains in place, the minotaur moves randomly\n",
    "                        states.append(((self.states[state][0][0], self.states[state][0][1]), (rows_minotaur[i], cols_minotaur[i]), self.states[state][2]))\n",
    "\n",
    "                return states\n",
    "          \n",
    "            else: # The action is possible, the player and the minotaur both move\n",
    "                states = []\n",
    "                for i in range(len(rows_minotaur)):\n",
    "                \n",
    "                    if row_player == rows_minotaur[i] and col_player == cols_minotaur[i]:\n",
    "                        states.append('Eaten')\n",
    "                    \n",
    "                    elif self.maze[row_player,col_player] == 2 and self.states[state][2] == 1:\n",
    "                        states.append('Win')\n",
    "                    \n",
    "                    elif self.maze[row_player, col_player] == 3:\n",
    "\n",
    "                        states.append(((row_player, col_player), (rows_minotaur[i], cols_minotaur[i]), 1))\n",
    "                    else:\n",
    "                        states.append(((row_player, col_player), (rows_minotaur[i], cols_minotaur[i]), self.states[state][2]))\n",
    "              \n",
    "                return states\n",
    "        \n",
    "    \n",
    "    def next_state(self, state, action):\n",
    "        moves = self.__move(state, action)\n",
    "        \n",
    "        if \"Terminal\" in moves:\n",
    "            return \"Terminal\"\n",
    "\n",
    "        if np.random.rand() <= 0.35:\n",
    "\n",
    "            if \"Eaten\" in moves:\n",
    "                return \"Eaten\"\n",
    "\n",
    "            if \"Win\" in moves:\n",
    "                return \"Win\"\n",
    "\n",
    "            dists = []\n",
    "            for move in moves:\n",
    "\n",
    "                dists.append(np.linalg.norm(np.array(move[0])-np.array(move[1]), ord=1))\n",
    "            \n",
    "            dists = np.array(dists)\n",
    "\n",
    "            closer_inds = np.argwhere(dists == np.min(dists))\n",
    "\n",
    "            \n",
    "            moves_closer  = [moves[i[0]] for i in closer_inds]\n",
    "\n",
    "            return random.choice(moves_closer)\n",
    "   \n",
    "        else:\n",
    "            return random.choice(moves)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def __transitions(self):\n",
    "        \"\"\" Computes the transition probabilities for every state action pair.\n",
    "            :return numpy.tensor transition probabilities: tensor of transition\n",
    "            probabilities of dimension S*S*A\n",
    "        \"\"\"\n",
    "        # Initialize the transition probailities tensor (S,S,A)\n",
    "        dimensions = (self.n_states,self.n_states,self.n_actions)\n",
    "        transition_probabilities = np.zeros(dimensions)\n",
    "  \n",
    "        for s in range(self.n_states):\n",
    "            for a in range(self.n_actions):\n",
    "                possible_moves = self.__move(s,a)\n",
    "                for s_prime in possible_moves:\n",
    "                    transition_probabilities[self.map[s_prime],s,a] += 1/len(possible_moves)\n",
    "    \n",
    "        return transition_probabilities\n",
    "\n",
    "\n",
    "\n",
    "    def __rewards(self):\n",
    "        \n",
    "        \"\"\" Computes the rewards for every state action pair \"\"\"\n",
    "\n",
    "        rewards = np.zeros((self.n_states, self.n_actions))\n",
    "        \n",
    "        for s in range(self.n_states):\n",
    "            for a in range(self.n_actions):\n",
    "                \n",
    "                if self.states[s] == 'Eaten': # The player has been eaten\n",
    "                    rewards[s, a] = self.MINOTAUR_REWARD\n",
    "                \n",
    "                elif self.states[s] == 'Win': # The player has won\n",
    "                    rewards[s, a] = self.GOAL_REWARD\n",
    "\n",
    "                elif self.states[s] == 'Terminal':\n",
    "                    continue\n",
    "\n",
    "                else:                \n",
    "                    next_states = self.__move(s,a)\n",
    "                    next_s = next_states[0] # The reward does not depend on the next position of the minotaur, we just consider the first one\n",
    "                    \n",
    "                    if self.states[s][0] == next_s[0] and a != self.STAY: # The player hits a wall\n",
    "                        rewards[s, a] = self.IMPOSSIBLE_REWARD\n",
    "                    \n",
    "                    else: # Regular move\n",
    "                        rewards[s, a] = self.STEP_REWARD\n",
    "\n",
    "        return rewards\n",
    "\n",
    "\n",
    "    #def step(self, action):\n",
    "    #    next_states = self.__move(self.states(s, a) \n",
    "\n",
    "\n",
    "    def simulate(self, start, policy, method):\n",
    "        \n",
    "        if method not in methods:\n",
    "            error = 'ERROR: the argument method must be in {}'.format(methods)\n",
    "            raise NameError(error)\n",
    "\n",
    "        path = list()\n",
    "        \n",
    "        if method == 'DynProg':\n",
    "            horizon = policy.shape[1] # Deduce the horizon from the policy shape\n",
    "            t = 0 # Initialize current time\n",
    "            s = self.map[start] # Initialize current state \n",
    "            path.append(start) # Add the starting position in the maze to the path\n",
    "            \n",
    "            while t < horizon - 1:\n",
    "                a = policy[s, t] # Move to next state given the policy and the current state\n",
    "                next_states = self.__move(s, a) \n",
    "                next_s = random.choice(next_states)\n",
    "                path.append(next_s) # Add the next state to the path\n",
    "                t +=1 # Update time and state for next iteration\n",
    "                s = self.map[next_s]\n",
    "                \n",
    "        if method == 'ValIter': \n",
    "            t = 1 # Initialize current state, next state and time\n",
    "            s = self.map[start]\n",
    "            path.append(start) # Add the starting position in the maze to the path\n",
    "            next_states = self.__move(s, policy[s]) # Move to next state given the policy and the current state\n",
    "            next_s = random.choice(next_states)\n",
    "            path.append(next_s) # Add the next state to the path\n",
    "            \n",
    "            horizon = np.random.geometric(1/30) # Question e\n",
    "            # Loop while state is not the goal state\n",
    "            while s != next_s and t <= horizon: # TODO change to is s_win or s_eaten /Viktor\n",
    "                s = self.map[next_s] # Update state\n",
    "                next_states = self.__move(s, policy[s]) # Move to next state given the policy and the current state\n",
    "                next_s = random.choice(next_states)\n",
    "                path.append(next_s) # Add the next state to the path\n",
    "                t += 1 # Update time for next iteration\n",
    "    \n",
    "        if method == 'Q_learning':\n",
    "            t = 1 # Initialize current state, next state and time\n",
    "            s = self.map[start]\n",
    "            path.append(start) # Add the starting position in the maze to the path\n",
    "            next_s = self.next_state(s, policy[s]) # Move to next state given the policy and the current state\n",
    "            path.append(next_s) # Add the next state to the path\n",
    "            \n",
    "            horizon = np.random.geometric(1/50) # Question e\n",
    "            \n",
    "            # Loop while state is not the goal state\n",
    "            while s != next_s and t <= horizon: # TODO change to is s_win or s_eaten /Viktor\n",
    "                s = self.map[next_s] # Update state\n",
    "                next_s = self.next_state(s, policy[s]) # Move to next state given the policy and the current state\n",
    "                path.append(next_s) # Add the next state to the path\n",
    "                t += 1 # Update time for next iteration\n",
    "\n",
    "        \n",
    "        \n",
    "        return [path, horizon] # Return the horizon as well, to plot the histograms for the VI\n",
    "\n",
    "\n",
    "\n",
    "    def show(self):\n",
    "        print('The states are :')\n",
    "        print(self.states)\n",
    "        print('The actions are:')\n",
    "        print(self.actions)\n",
    "        print('The mapping of the states:')\n",
    "        print(self.map)\n",
    "        print('The rewards:')\n",
    "        print(self.rewards)\n",
    "\n",
    "\n",
    "\n",
    "def dynamic_programming(env, horizon):\n",
    "    \"\"\" Solves the shortest path problem using dynamic programming\n",
    "        :input Maze env           : The maze environment in which we seek to\n",
    "                                    find the shortest path.\n",
    "        :input int horizon        : The time T up to which we solve the problem.\n",
    "        :return numpy.array V     : Optimal values for every state at every\n",
    "                                    time, dimension S*T\n",
    "        :return numpy.array policy: Optimal time-varying policy at every state,\n",
    "                                    dimension S*T\n",
    "    \"\"\"\n",
    "\n",
    "    V = np.zeros((env.n_states,horizon))\n",
    "    policy = np.zeros((env.n_states,horizon))\n",
    "\n",
    "    V[:, horizon-1] = np.max(env.rewards, axis=1)\n",
    "    policy[:,horizon-1] = np.argmax(env.rewards, axis=1)\n",
    "\n",
    "    for t in range(horizon-2,-1,-1):\n",
    "        # max(rewards + transition[s_prime,s,a] * V[s_prime,t+1], axis=a)\n",
    "        Q = env.rewards + (env.transition_probabilities.T @ V[:,t+1]).T\n",
    "        V[:,t] = np.max(Q, axis=1)\n",
    "        policy[:,t] = np.argmax(Q, axis=1)\n",
    "\n",
    "    return V, policy\n",
    "\n",
    "\n",
    "def value_iteration(env, gamma, epsilon):\n",
    "    \"\"\" Solves the shortest path problem using value iteration\n",
    "        :input Maze env           : The maze environment in which we seek to\n",
    "                                    find the shortest path.\n",
    "        :input float gamma        : The discount factor.\n",
    "        :input float epsilon      : accuracyhorizon of the value iteration procedure.\n",
    "        :return numpy.array V     : Optimal values for every state at every\n",
    "                                    time, dimension S\n",
    "        :return numpy.array policy: Optimal time-varying policy at every state,\n",
    "                                    dimension S\n",
    "    \"\"\"\n",
    "\n",
    "    V = np.zeros(env.n_states)\n",
    "    err = epsilon*(1-gamma)/gamma + 1\n",
    "\n",
    "    while err > epsilon*(1-gamma)/gamma:\n",
    "        new_V = np.max(env.rewards + gamma*(env.transition_probabilities.T @ V).T, axis=1)\n",
    "        err = np.linalg.norm(new_V - V)\n",
    "        V = new_V\n",
    "    \n",
    "    policy = np.argmax(env.rewards + gamma*(env.transition_probabilities.T @ V).T, axis=1)\n",
    "\n",
    "    return V, policy\n",
    "\n",
    "\n",
    "#Choose action based on epsilon-greedy policy\n",
    "\n",
    "def choose_action(env, state, q_value, eps):\n",
    "    if np.random.binomial(1, eps) == 1:\n",
    "        return np.random.choice(env.n_actions)  # Random action\n",
    "    else:\n",
    "        values_ = q_value[state, :]\n",
    "        return np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)])\n",
    "\n",
    "\n",
    "# Q-Learning update rule\n",
    "\"\"\"\n",
    "def q_learning(env, q_value, step_size, gamma):\n",
    "    state = env.reset()[0]  # Initial state\n",
    "    done, truncated = False, False\n",
    "    while not (done or truncated):\n",
    "        action = choose_action(state, q_value)\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "        q_value[state, action] += step_size * (reward + gamma * np.max(q_value[next_state, :]) - q_value[state, action])\n",
    "        state = next_state\n",
    "    return q_value\n",
    "\"\"\"\n",
    "\n",
    "def q_learning(env, start_state, alpha, q_value, gamma, eps):\n",
    "    #t=1\n",
    "    visits = np.ones((env.n_states, env.n_actions))\n",
    "\n",
    "    state = env.map[start_state]  # Initial state\n",
    "    #print(state)\n",
    "    while env.states[state] != \"Terminal\": #and t <= horizon:\n",
    "        a = choose_action(env, state, q_value, eps)\n",
    "        next_s = env.map[env.next_state(state, a)] \n",
    "        reward = env.rewards[state, a]\n",
    "        q_value[state, a] += 1/visits[state, a]**alpha * (reward + gamma * np.max(q_value[next_s, :]) - q_value[state, a])\n",
    "        state = next_s\n",
    "        visits[state, a] += 1\n",
    "        #t+=1\n",
    "\n",
    "    return q_value\n",
    "\n",
    "def animate_solution(maze, path):\n",
    "\n",
    "    # Map a color to each cell in the maze\n",
    "    col_map = {0: WHITE, 1: BLACK, 2: LIGHT_GREEN, -1: LIGHT_RED, -2: LIGHT_PURPLE}\n",
    "    \n",
    "    rows, cols = maze.shape # Size of the maze\n",
    "    fig = plt.figure(1, figsize=(cols, rows)) # Create figure of the size of the maze\n",
    "\n",
    "    # Remove the axis ticks and add title\n",
    "    ax = plt.gca()\n",
    "    ax.set_title('Policy simulation')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Give a color to each cell\n",
    "    colored_maze = [[col_map[maze[j, i]] for i in range(cols)] for j in range(rows)]\n",
    "\n",
    "    # Create a table to color\n",
    "    grid = plt.table(\n",
    "        cellText = None, \n",
    "        cellColours = colored_maze, \n",
    "        cellLoc = 'center', \n",
    "        loc = (0,0), \n",
    "        edges = 'closed'\n",
    "    )\n",
    "    \n",
    "    # Modify the height and width of the cells in the table\n",
    "    tc = grid.properties()['children']\n",
    "    for cell in tc:\n",
    "        cell.set_height(1.0/rows)\n",
    "        cell.set_width(1.0/cols)\n",
    "\n",
    "    for i in range(0, len(path)):\n",
    "        if path[i-1] not in ('Eaten', 'Win', 'Terminal'):\n",
    "            grid.get_celld()[(path[i-1][0])].set_facecolor(col_map[maze[path[i-1][0]]])\n",
    "            grid.get_celld()[(path[i-1][1])].set_facecolor(col_map[maze[path[i-1][1]]])\n",
    "        if path[i] not in ('Eaten', 'Win', 'Terminal'):\n",
    "            grid.get_celld()[(path[i][0])].set_facecolor(col_map[-2]) # Position of the player\n",
    "            grid.get_celld()[(path[i][1])].set_facecolor(col_map[-1]) # Position of the minotaur\n",
    "        display.display(fig)\n",
    "        time.sleep(0.1)\n",
    "        display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490ab984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_Q(env, maze):\n",
    "    key_cords = np.argwhere(maze == 3)[0]#(0, 7)\n",
    "    exit_cords = np.argwhere(maze == 2)[0]\n",
    "\n",
    "    Q_init = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "    for i in range(env.n_states-3):\n",
    "        (player_cords, minotaur_cords, key) = env.states[i]\n",
    "        if key == 0:\n",
    "            Q_init[i,:] = 0.5*(1-np.linalg.norm(np.array(player_cords) - np.array(key_cords), ord=1)/15)\n",
    "\n",
    "\n",
    "    for i in range(env.n_states-3):\n",
    "        (player_cords, minotaur_cords, key) = env.states[i]\n",
    "        if key == 1:\n",
    "            Q_init[i,:] = 1-np.linalg.norm(np.array(player_cords) - np.array(exit_cords), ord=1)/30\n",
    "\n",
    "    \n",
    "\n",
    "    Q_init[env.map[\"Win\"],:] = 1\n",
    "\n",
    "    return Q_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a142b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode iter  0\n",
      "episode iter  1000\n",
      "episode iter  2000\n",
      "episode iter  3000\n",
      "episode iter  4000\n",
      "episode iter  5000\n",
      "episode iter  6000\n",
      "episode iter  7000\n",
      "episode iter  8000\n",
      "episode iter  9000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Q-learning\n",
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 3],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "# With the convention 0 = empty cell, 1 = obstacle, 2 = exit of the Maze\n",
    "\n",
    "env = Maze(maze) # Create an environment maze\n",
    "gamma= 49/50\n",
    "eps = 0.1\n",
    "step_size = 0.01\n",
    "\n",
    "\n",
    "q_q_learning = init_Q(env, maze)\n",
    "#q_q_learning = np.zeros((env.n_states, env.n_actions))\n",
    "\n",
    "#print(q_q_learning)\n",
    "\n",
    "start  = ((0,0), (6,5), 0)\n",
    "\n",
    "episodes = 10000\n",
    "for i in range(episodes):\n",
    "    \"q_learning(env, start_state, alpha, q_value, step_size, gamma, eps)\"\n",
    "    q_q_learning = q_learning(env, start, 2/3, q_q_learning, gamma, eps) #np.random.geometric(1/50)\n",
    "    if i % 1000 == 0:\n",
    "        print(\"episode iter \", i)\n",
    "\n",
    "\n",
    "q_learning_policy = np.argmax(q_q_learning, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a5fddc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate the shortest path starting from position A\n",
    "\n",
    "\n",
    "path, horizon = env.simulate(start, q_learning_policy, \"Q_learning\")\n",
    "\n",
    "horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1b78475",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m maze = np.array([\n\u001b[32m      2\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m      3\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m],\n\u001b[32m      8\u001b[39m     [\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]])\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43manimate_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 449\u001b[39m, in \u001b[36manimate_solution\u001b[39m\u001b[34m(maze, path)\u001b[39m\n\u001b[32m    447\u001b[39m     grid.get_celld()[(path[i][\u001b[32m0\u001b[39m])].set_facecolor(col_map[-\u001b[32m2\u001b[39m]) \u001b[38;5;66;03m# Position of the player\u001b[39;00m\n\u001b[32m    448\u001b[39m     grid.get_celld()[(path[i][\u001b[32m1\u001b[39m])].set_facecolor(col_map[-\u001b[32m1\u001b[39m]) \u001b[38;5;66;03m# Position of the minotaur\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[43mdisplay\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m time.sleep(\u001b[32m0.1\u001b[39m)\n\u001b[32m    451\u001b[39m display.clear_output(wait = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/IPython/core/display_functions.py:278\u001b[39m, in \u001b[36mdisplay\u001b[39m\u001b[34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[39m\n\u001b[32m    276\u001b[39m     publish_display_data(data=obj, metadata=metadata, **kwargs)\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     format_dict, md_dict = \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[32m    280\u001b[39m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:238\u001b[39m, in \u001b[36mDisplayFormatter.format\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m    236\u001b[39m md = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     data = \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:282\u001b[39m, in \u001b[36mcatch_format_error\u001b[39m\u001b[34m(method, self, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     r = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/backend_bases.py:2186\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2182\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2183\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2184\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2186\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2193\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/backend_bases.py:2042\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2038\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2040\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2041\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2042\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2043\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2044\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2045\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:429\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    425\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     mpl.image.imsave(\n\u001b[32m    431\u001b[39m         filename_or_obj, \u001b[38;5;28mself\u001b[39m.buffer_rgba(), \u001b[38;5;28mformat\u001b[39m=fmt, origin=\u001b[33m\"\u001b[39m\u001b[33mupper\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         dpi=\u001b[38;5;28mself\u001b[39m.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:382\u001b[39m, in \u001b[36mFigureCanvasAgg.draw\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.toolbar._wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.toolbar\n\u001b[32m    381\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28msuper\u001b[39m().draw()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:3226\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3224\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3226\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3229\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3230\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/table.py:413\u001b[39m, in \u001b[36mTable.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28mself\u001b[39m._update_positions(renderer)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m._cells):\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cells\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/table.py:148\u001b[39m, in \u001b[36mCell.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28msuper\u001b[39m().draw(renderer)\n\u001b[32m    147\u001b[39m \u001b[38;5;66;03m# position the text\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_text_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m._text.draw(renderer)\n\u001b[32m    150\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/table.py:156\u001b[39m, in \u001b[36mCell._set_text_position\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m    154\u001b[39m bbox = \u001b[38;5;28mself\u001b[39m.get_window_extent(renderer)\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# center vertically\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m y = \u001b[43mbbox\u001b[49m\u001b[43m.\u001b[49m\u001b[43my0\u001b[49m + bbox.height / \u001b[32m2\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# position horizontally\u001b[39;00m\n\u001b[32m    158\u001b[39m loc = \u001b[38;5;28mself\u001b[39m._text.get_horizontalalignment()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/matplotlib/transforms.py:250\u001b[39m, in \u001b[36mBboxBase.y0\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    The first of the pair of *x* coordinates that define the bounding box.\u001b[39;00m\n\u001b[32m    244\u001b[39m \n\u001b[32m    245\u001b[39m \u001b[33;03m    This is not guaranteed to be less than :attr:`x1` (for that, use\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[33;03m    :attr:`xmin`).\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_points()[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34my0\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    The first of the pair of *y* coordinates that define the bounding box.\u001b[39;00m\n\u001b[32m    254\u001b[39m \n\u001b[32m    255\u001b[39m \u001b[33;03m    This is not guaranteed to be less than :attr:`y1` (for that, use\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[33;03m    :attr:`ymin`).\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_points()[\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "\n",
    "print(path)\n",
    "animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e30d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0), (6, 5), 0),\n",
       " ((0, 1), (6, 4), 0),\n",
       " ((0, 1), (6, 5), 0),\n",
       " ((1, 1), (5, 5), 0),\n",
       " ((0, 1), (6, 5), 0),\n",
       " ((1, 1), (6, 4), 0),\n",
       " ((1, 1), (6, 5), 0),\n",
       " ((2, 1), (6, 6), 0),\n",
       " ((3, 1), (6, 5), 0),\n",
       " ((4, 1), (6, 4), 0),\n",
       " ((4, 0), (5, 4), 0),\n",
       " ((4, 1), (5, 5), 0),\n",
       " ((4, 1), (5, 4), 0),\n",
       " ((4, 1), (4, 4), 0),\n",
       " ((4, 1), (4, 3), 0),\n",
       " ((4, 1), (3, 3), 0),\n",
       " ((4, 1), (2, 3), 0),\n",
       " ((4, 1), (2, 2), 0),\n",
       " ((4, 1), (3, 2), 0),\n",
       " ((4, 1), (3, 1), 0),\n",
       " ((4, 1), (3, 2), 0),\n",
       " ((4, 1), (2, 2), 0),\n",
       " ((4, 1), (3, 2), 0),\n",
       " ((4, 1), (2, 2), 0),\n",
       " ((4, 1), (2, 1), 0),\n",
       " ((4, 1), (2, 0), 0),\n",
       " ((4, 1), (2, 1), 0),\n",
       " ((4, 1), (3, 1), 0),\n",
       " ((4, 1), (2, 1), 0),\n",
       " ((4, 1), (3, 1), 0),\n",
       " ((4, 1), (3, 0), 0),\n",
       " ((4, 1), (2, 0), 0),\n",
       " ((4, 1), (1, 0), 0),\n",
       " ((4, 1), (0, 0), 0),\n",
       " ((4, 1), (0, 1), 0),\n",
       " ((4, 1), (0, 0), 0),\n",
       " ((4, 1), (0, 1), 0),\n",
       " ((4, 1), (0, 2), 0),\n",
       " ((4, 1), (0, 3), 0),\n",
       " ((4, 1), (0, 4), 0),\n",
       " ((4, 1), (1, 4), 0),\n",
       " ((4, 1), (2, 4), 0),\n",
       " ((4, 1), (1, 4), 0),\n",
       " ((4, 1), (2, 4), 0),\n",
       " ((4, 1), (3, 4), 0),\n",
       " ((4, 1), (4, 4), 0),\n",
       " ((4, 1), (4, 5), 0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972da454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ValIter and DP \n",
    "if __name__ == \"__main__\":\n",
    "    # Description of the maze as a numpy array\n",
    "    maze = np.array([\n",
    "        [0, 0, 1, 0, 0, 0, 0, 3],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "    # With the convention 0 = empty cell, 1 = obstacle, 2 = exit of the Maze\n",
    "    \n",
    "    env = Maze(maze) # Create an environment maze\n",
    "    horizon = 40\n",
    "\n",
    "    # Solve the MDP problem with dynamic programming\n",
    "    method = 'DynProg'\n",
    "    V, policy = dynamic_programming(env, horizon) \n",
    "\n",
    "    # Solve the MDP problem with value iteration\n",
    "    gamma = 29/30\n",
    "    epsilon = 1e-3\n",
    "    #method = \"ValIter\"\n",
    "    #V, policy = value_iteration(env, gamma, epsilon)\n",
    "\n",
    "    # Simulate the shortest path starting from position A\n",
    "    start  = ((0,0), (6,5), 0)\n",
    "    path = env.simulate(start, policy, method)[0]\n",
    "\n",
    "    maze = np.array([\n",
    "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "        [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "        [0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "\n",
    "    print(path)\n",
    "    animate_solution(maze, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa099db",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m n = \u001b[32m100000\u001b[39m\n\u001b[32m     21\u001b[39m survives = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m V, policy = \u001b[43mvalue_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mgamma = \u001b[39m\u001b[33m\"\u001b[39m, gamma)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,n):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 292\u001b[39m, in \u001b[36mvalue_iteration\u001b[39m\u001b[34m(env, gamma, epsilon)\u001b[39m\n\u001b[32m    289\u001b[39m err = epsilon*(\u001b[32m1\u001b[39m-gamma)/gamma + \u001b[32m1\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m err > epsilon*(\u001b[32m1\u001b[39m-gamma)/gamma:\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     new_V = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransition_probabilities\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     err = np.linalg.norm(new_V - V)\n\u001b[32m    294\u001b[39m     V = new_V\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EL2805/EL2805_Labs/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3047\u001b[39m, in \u001b[36m_max_dispatcher\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3043\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mkeepdims\u001b[39m\u001b[33m'\u001b[39m] = keepdims\n\u001b[32m   3044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _methods._ptp(a, axis=axis, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_max_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m, initial=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3048\u001b[39m                     where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[32m   3052\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[32m   3053\u001b[39m \u001b[38;5;129m@set_module\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3054\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmax\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, initial=np._NoValue,\n\u001b[32m   3055\u001b[39m          where=np._NoValue):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Description of the maze as a numpy array\n",
    "maze = np.array([\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 0]])\n",
    "# With the convention 0 = empty cell, 1 = obstacle, 2 = exit of the Maze\n",
    "\n",
    "env = Maze(maze) # Create an environment maze\n",
    "\n",
    "gammas = np.array([29/30])\n",
    "gamma_probs = []\n",
    "\n",
    "epsilon = 0.001\n",
    "\n",
    "for gamma in gammas:\n",
    "    n = 100000\n",
    "    survives = 0\n",
    "    V, policy = value_iteration(env, gamma, epsilon)\n",
    "    print(\"gamma = \", gamma)\n",
    "    for i in range(0,n):\n",
    "        method = \"ValIter\"\n",
    "        path, horizon = env.simulate(start, policy, method)\n",
    "        if \"Win\" in path and 'Terminal' in path:\n",
    "            survives += 1\n",
    "    \n",
    "    \n",
    "    gamma_probs.append(survives/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c11f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.62193]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f96a8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.622120345492098)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[env.map[start]]*30/29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
